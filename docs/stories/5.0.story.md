# Story 5.0: Python Backend Foundation

**Epic:** 5 - AI-Powered Messaging Features  
**Story Points:** 8  
**Priority:** Critical  
**Assigned To:** @dev  
**Status:** Done

---

## User Story

**As a** developer,  
**I want** a Python backend with FastAPI, LangChain, and Pinecone configured,  
**so that** I can implement AI-powered features that analyze messages and provide intelligent suggestions.

---

## Description

Set up the foundational infrastructure for all AI features. This includes creating a Python backend server with FastAPI, integrating LangChain for LLM orchestration, configuring Pinecone for vector storage, and establishing the connection between the iOS app and the backend.

This story is purely infrastructure - no user-facing AI features yet, but creates the platform on which all subsequent AI stories depend.

---

## Acceptance Criteria

### AC1: Python Backend Structure Created
- [ ] `python-backend/` directory created with proper structure
- [ ] Directory structure matches technical spec:
  - `app/main.py` - FastAPI entry point
  - `app/routes/` - API endpoint modules
  - `app/services/` - Business logic layer
  - `app/models/` - Pydantic data models
  - `requirements.txt` - Python dependencies
  - `.env.example` - Example environment variables
  - `.gitignore` - Excludes `.env` and Python artifacts

### AC2: Dependencies Installed and Configured
- [ ] `requirements.txt` includes all required packages:
  - fastapi>=0.109.0
  - uvicorn[standard]>=0.27.0
  - langchain>=0.1.4
  - langchain-openai>=0.0.5
  - langchain-pinecone>=0.0.1
  - pinecone-client>=3.0.0
  - openai>=1.12.0
  - pydantic>=2.5.0
  - python-dotenv>=1.0.0
- [ ] All dependencies install without errors
- [ ] Virtual environment created and documented

### AC3: FastAPI Application Running
- [ ] Basic FastAPI app created in `app/main.py`
- [ ] Health check endpoint: `GET /health`
- [ ] CORS middleware configured for iOS app
- [ ] Swagger docs accessible at `/docs`
- [ ] Server runs locally on port 8000
- [ ] No errors in startup logs

### AC4: Pinecone Configured
- [ ] Pinecone account created (free tier)
- [ ] Pinecone API key obtained
- [ ] Index "messageai" created with:
  - Dimensions: 1536
  - Metric: cosine
  - Cloud: AWS
  - Region: us-east-1 (or appropriate)
- [ ] Connection test successful from Python
- [ ] Pinecone client initialized in `app/services/vector_store.py`

### AC5: OpenAI API Integrated
- [ ] OpenAI API key configured in `.env`
- [ ] OpenAI client initialized
- [ ] Test embedding generation working
- [ ] Test chat completion working
- [ ] Embeddings model: text-embedding-3-small
- [ ] Chat model: gpt-4o-mini

### AC6: LangChain Setup
- [ ] LangChain OpenAI integration configured
- [ ] LangChain Pinecone integration configured
- [ ] Test vector store creation successful
- [ ] Vector similarity search working (foundation for lightweight RAG)

### AC7: Environment Configuration
- [ ] `.env` file created (gitignored)
- [ ] `.env.example` provided with template
- [ ] Environment variables:
  - `OPENAI_API_KEY`
  - `PINECONE_API_KEY`
  - `PINECONE_ENVIRONMENT`
  - `HOST` (0.0.0.0)
  - `PORT` (8000)
  - `DEBUG` (true)
- [ ] Environment validation on startup
- [ ] Fails fast if required keys missing

### AC8: iOS Backend Service Created
- [ ] `AIBackendService.swift` created in `ios-app/MessageAI/Services/`
- [ ] HTTP client using URLSession
- [ ] Base URL configurable (localhost for dev, production for deploy)
- [ ] Test endpoint call to `/health` working
- [ ] Proper error handling for network failures
- [ ] Async/await pattern used

### AC9: Deployment Ready
- [ ] `python-backend/README.md` created with:
  - Setup instructions
  - How to run locally
  - How to deploy to Render.com
  - Environment variable documentation
- [ ] Render.com account created
- [ ] Backend deployed to Render.com
- [ ] Production URL obtained
- [ ] Health check accessible from production URL

### AC10: Testing Infrastructure
- [ ] `tests/` directory created
- [ ] pytest configured
- [ ] Sample test file created
- [ ] Tests can be run with `pytest`
- [ ] CI-ready (even if not CI yet)

---

## Tasks

### Task 1: Project Setup (AC1, AC2)
- [ ] Create `python-backend/` directory
- [ ] Initialize git in subdirectory
- [ ] Create directory structure
- [ ] Create `requirements.txt`
- [ ] Create `.env.example`
- [ ] Create `.gitignore`
- [ ] Update root `.gitignore` to include `python-backend/.env`
- [ ] Create virtual environment: `python3 -m venv venv`
- [ ] Activate venv: `source venv/bin/activate`
- [ ] Install dependencies: `pip install -r requirements.txt`

### Task 2: FastAPI Application (AC3)
- [ ] Create `app/__init__.py`
- [ ] Create `app/main.py` with FastAPI app
- [ ] Add CORS middleware
- [ ] Create health check endpoint
- [ ] Test locally: `uvicorn app.main:app --reload`
- [ ] Verify `/health` returns 200
- [ ] Verify `/docs` shows Swagger UI

### Task 3: Pinecone Setup (AC4)
- [ ] Sign up for Pinecone free tier
- [ ] Create API key
- [ ] Create index "messageai" via dashboard
- [ ] Add `PINECONE_API_KEY` to `.env`
- [ ] Create `app/services/__init__.py`
- [ ] Create `app/services/vector_store.py`
- [ ] Initialize Pinecone client
- [ ] Test connection with sample vector upsert
- [ ] Verify vector appears in Pinecone dashboard

### Task 4: OpenAI Integration (AC5)
- [ ] Add `OPENAI_API_KEY` to `.env`
- [ ] Create `app/services/openai_service.py`
- [ ] Test embedding generation
- [ ] Test chat completion
- [ ] Verify API calls succeed
- [ ] Add error handling for API failures

### Task 5: LangChain Configuration (AC6)
- [ ] Import LangChain components
- [ ] Create `OpenAIEmbeddings` instance
- [ ] Create `PineconeVectorStore` instance
- [ ] Test adding document to vector store
- [ ] Test similarity search with filters
- [ ] Verify `search_similar_messages()` method works
- [ ] Note: Full RAG chains will be implemented in future stories as needed

### Task 6: API Routes Scaffolding (AC3)
- [ ] Create `app/routes/__init__.py`
- [ ] Create `app/routes/analysis.py` (empty)
- [ ] Create `app/routes/summarization.py` (empty)
- [ ] Create `app/routes/events.py` (empty)
- [ ] Create `app/routes/reminders.py` (empty)
- [ ] Create `app/routes/decisions.py` (empty)
- [ ] Create `app/routes/agent.py` (empty)
- [ ] Register all routers in `main.py`

### Task 7: Data Models (AC2)
- [ ] Create `app/models/__init__.py`
- [ ] Create `app/models/requests.py` with Pydantic models
- [ ] Create `app/models/responses.py` with Pydantic models
- [ ] Create `app/models/database.py` for internal models

### Task 8: iOS Service (AC8)
- [ ] Create `AIBackendService.swift`
- [ ] Add `AI_BACKEND_URL` to `Config.xcconfig`
- [ ] Implement health check method
- [ ] Test calling backend from iOS simulator
- [ ] Add proper error types
- [ ] Add async/await wrappers

### Task 9: Deployment (AC9)
- [ ] Create Render.com account
- [ ] Connect GitHub repo to Render
- [ ] Configure web service:
  - Build command: `pip install -r python-backend/requirements.txt`
  - Start command: `cd python-backend && uvicorn app.main:app --host 0.0.0.0 --port $PORT`
  - Root directory: `python-backend`
- [ ] Add environment variables in Render dashboard
- [ ] Deploy
- [ ] Verify production URL works
- [ ] Update iOS `Config.xcconfig` with production URL option

### Task 10: Documentation & Testing (AC10)
- [ ] Write `python-backend/README.md`
- [ ] Create `tests/test_health.py`
- [ ] Run tests locally
- [ ] Document all environment variables
- [ ] Add troubleshooting section to README

---

## Technical Notes

### FastAPI App Structure
```python
# app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

load_dotenv()

app = FastAPI(title="MessageAI Backend", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly for production
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def root():
    return {"message": "MessageAI Backend", "status": "running"}

@app.get("/health")
def health():
    return {"status": "healthy"}
```

### Vector Store Service Template
```python
# app/services/vector_store.py
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone
import os

class VectorStoreService:
    def __init__(self):
        pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        self.index = pc.Index("messageai")
        
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        self.messages_store = PineconeVectorStore(
            index=self.index,
            embedding=self.embeddings,
            namespace="messages"
        )
```

### iOS Backend Service Template
```swift
// Services/AIBackendService.swift
import Foundation

class AIBackendService {
    private let baseURL: String
    private let session: URLSession
    
    init(baseURL: String = "http://localhost:8000") {
        self.baseURL = baseURL
        self.session = URLSession.shared
    }
    
    func healthCheck() async throws -> HealthResponse {
        let url = URL(string: "\(baseURL)/health")!
        let (data, _) = try await session.data(from: url)
        return try JSONDecoder().decode(HealthResponse.self, from: data)
    }
}

struct HealthResponse: Codable {
    let status: String
}
```

### Render.com Configuration
```yaml
# render.yaml (optional)
services:
  - type: web
    name: messageai-backend
    env: python
    region: oregon
    plan: free
    buildCommand: "pip install -r requirements.txt"
    startCommand: "uvicorn app.main:app --host 0.0.0.0 --port $PORT"
    envVars:
      - key: OPENAI_API_KEY
        sync: false
      - key: PINECONE_API_KEY
        sync: false
      - key: PINECONE_ENVIRONMENT
        value: us-east-1
```

---

## Definition of Done

- [ ] All acceptance criteria met
- [ ] All tasks completed and checked off
- [ ] Python backend runs locally without errors
- [ ] Backend deployed to Render.com successfully
- [ ] iOS app can call backend health endpoint
- [ ] Pinecone index created and accessible
- [ ] OpenAI API calls working
- [ ] LangChain integration tested
- [ ] README documentation complete
- [ ] No API keys committed to git
- [ ] `.gitignore` properly configured
- [ ] Code follows Python PEP 8 standards
- [ ] Manual testing passed

---

## Dependencies

**Upstream:** None (this is the foundation story)

**Downstream:** All other AI stories (5.1-5.6) depend on this

---

## Risks

- **Pinecone setup complexity:** Mitigation - Follow official docs, use free tier limits
- **Render.com deployment issues:** Mitigation - Test locally first, use their support
- **LangChain version conflicts:** Mitigation - Pin specific versions in requirements.txt
- **Environment variable management:** Mitigation - Clear documentation in README

---

## Testing Strategy

### Manual Testing (Primary Validation)
1. Start backend locally: `uvicorn app.main:app --reload`
2. Open browser to `http://localhost:8000/docs`
3. Test health endpoint from Swagger UI
4. Run iOS app, call health check from simulator
5. Check Pinecone dashboard for test vectors
6. Verify OpenAI API calls in logs

### Unit Testing (Optional)
Unit tests may be created but are not required for this story. Focus is on manual validation.

```python
# tests/test_health.py (optional)
def test_health_endpoint():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}
```

**Note:** This story will rely on manual testing for validation. Unit tests are optional and may be skipped to meet timeline constraints.

---

## Notes

- This story is infrastructure-only, no user-facing features
- Focus on getting the foundation solid before building AI features
- Take time to test thoroughly - all subsequent stories depend on this
- Keep API keys secure - never commit to git
- Document everything in README for future reference

### Architectural Notes
- **Lightweight RAG Approach:** Future stories (especially 5.2 Decision Detection) will use vector search + context rather than full RAG chains
- **Summarization Route:** Created as stub only; may be implemented differently in post-MVP
- **Vector Search:** The `search_similar_messages()` method is the foundation for context-aware AI features

---

## References

- Technical Spec: `docs/architecture/ai-features-technical-spec.md`
- LangChain Docs: https://python.langchain.com/docs/
- Pinecone Docs: https://docs.pinecone.io/
- FastAPI Docs: https://fastapi.tiangolo.com/
- Render Deployment: https://render.com/docs/deploy-fastapi

---

**Story 5.0 is the critical foundation that enables all AI features. Get this right, and the rest will follow smoothly.**

